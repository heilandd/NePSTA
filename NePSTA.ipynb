{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMClL7sHHeqC"
      },
      "source": [
        "# ST Pathology GNN Network\n",
        "\n",
        "This notebook contains the full analysis of the ST Pathology framework. We start with the module to predict the Heidelberg classifier subgroups from spatially resolved transcriptomics using a 3-hop subgraph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0lGjQ4QHjEc",
        "outputId": "24c36a9e-1f6c-46a7-ed88-58544d12caa7"
      },
      "outputs": [],
      "source": [
        "## Install Pytorch geometric\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-cWwePyH71A"
      },
      "source": [
        "The input data are saved on the google Drive: We connect the google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StLOvmvyH7GI",
        "outputId": "cba40349-dfa4-42fb-f2d2-2208ee39b502"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmdpXRqwIExW"
      },
      "outputs": [],
      "source": [
        "## Import the network arcitectures\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/GIN_Train/Script')\n",
        "\n",
        "from GIN_ClassPred_V2_All_Functions import *\n",
        "from reduceNN import *\n",
        "from runQC import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF4kZ_O-nyHj"
      },
      "source": [
        "## Import data and run quality controll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IC83BzeYnxRz"
      },
      "outputs": [],
      "source": [
        "graph_train = torch.load(\"/content/drive/My Drive/GIN_Train/Data/Graph_Class_train.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv7QT_X_oCAP",
        "outputId": "a9fc731d-0ce4-4fc4-8267-7678e15d423b"
      },
      "outputs": [],
      "source": [
        "graph_train = runQC(graph_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LLkPsM-oF51",
        "outputId": "77ce4663-47dc-41bf-a26d-8e51018325de"
      },
      "outputs": [],
      "source": [
        "graph_NN1 = reduceNN(graph_train, hop=1)\n",
        "graph_NN2 = reduceNN(graph_train, hop=2)\n",
        "graph_NN3 = graph_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BRiPIg4doLeD",
        "outputId": "9082f011-6d5e-4d9f-c5ac-4300038ccaa8"
      },
      "outputs": [],
      "source": [
        "model_NN1 = RunTrainingGIN(graph_NN1, num_classes=11, epochs=200, batch_size=1500)\n",
        "torch.save(model_NN1, '/content/drive/My Drive/GIN_Train/Model/Class_model_NN1.pth')\n",
        "\n",
        "\n",
        "model_NN2 = RunTrainingGIN(graph_NN2, num_classes=11,epochs=200,batch_size=1500)\n",
        "torch.save(model_NN2, '/content/drive/My Drive/GIN_Train/Model/Class_model_NN2.pth')\n",
        "\n",
        "\n",
        "model_NN3 = RunTrainingGIN(graph_NN3, num_classes=11,epochs=200,batch_size=1500)\n",
        "torch.save(model_NN3, '/content/drive/My Drive/GIN_Train/Model/Class_model_NN3.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR63tkwdA14l",
        "outputId": "247290cd-4633-45bd-888c-e42dffb62b60"
      },
      "outputs": [],
      "source": [
        "# Validation\n",
        "\n",
        "graph_val = torch.load(\"/content/drive/My Drive/GIN_Train/Data/Graph_Class_val.pt\")\n",
        "graph_val = runQC(graph_val)\n",
        "graph_val_NN1 = reduceNN(graph_val, hop=1)\n",
        "graph_val_NN2 = reduceNN(graph_val, hop=2)\n",
        "graph_val_NN3 = graph_val\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoq24NnbBXCQ"
      },
      "source": [
        "## Run Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GqSe_keJZl0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch_geometric.utils as utils\n",
        "import matplotlib as PL\n",
        "from tqdm import tqdm\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.nn import BatchNorm1d, Linear\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.utils import add_self_loops\n",
        "from torch_geometric.data import Data\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINConv\n",
        "from torch.nn import Linear\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "import torch.nn as nn\n",
        "\n",
        "def RunEvaluationGINClass1(graph, model):\n",
        "\n",
        "  model.eval()\n",
        "  latent_space = []\n",
        "  class_out_logits = []\n",
        "  class_out_list = []\n",
        "\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"Running on:\", device)\n",
        "\n",
        "  model.to(device)\n",
        "  i=1\n",
        "\n",
        "  for data in tqdm(graph, desc=\"Eval\"):\n",
        "\n",
        "    #i=i+1\n",
        "    #print(i)\n",
        "    latent, class_out = model(data.to(device))\n",
        "\n",
        "    ## Latent space\n",
        "    latent_space.append(latent.mean(dim=0, keepdim=True).detach().cpu().numpy())\n",
        "\n",
        "    ## Status\n",
        "    class_out_logits.append(class_out.detach().cpu().numpy())\n",
        "    class_out_list.append(torch.argmax(class_out, dim=1).detach().cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "  return(np.concatenate(latent_space), np.concatenate(class_out_logits), np.concatenate(class_out_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JDi0PyyMs5O",
        "outputId": "0b720c46-3cb6-47e6-e116-f4afcb8d3a51"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvQE7M3vBH-k",
        "outputId": "72865169-8328-429e-d1ec-5d844e781d31"
      },
      "outputs": [],
      "source": [
        "val_NN1 = RunEvaluationGINClass1(graph_val_NN1, model_NN1)\n",
        "val_NN2 = RunEvaluationGINClass1(graph_val_NN2, model_NN2)\n",
        "val_NN3 = RunEvaluationGINClass1(graph_val_NN3, model_NN3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iT8hwu4BowS",
        "outputId": "900484ab-7141-4ab2-fcc1-dc7664fb47a6"
      },
      "outputs": [],
      "source": [
        "gt = []\n",
        "for i in tqdm(range(len(graph_val_NN1))):\n",
        "  gt.append(graph_val_NN1[i].Class.detach().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mqXUcKPB7GD",
        "outputId": "2bc2c1e3-b680-4cac-8984-2773d99b03bd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "predicted = val_NN1[2]\n",
        "labels = np.array(gt)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, predicted))\n",
        "print(\"Precision:\", precision_score(labels, predicted, average='macro'))\n",
        "print(\"Recall:\", recall_score(labels, predicted, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(labels, predicted, average='macro'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "yGC0xfoCNDGu",
        "outputId": "26a540a5-2069-44de-81cb-eec41a120e5b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(labels, predicted)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix: True vs Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "cSmxQ7JKCgUB",
        "outputId": "5d78c742-26a2-40c4-e4a8-5c812d97749e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "predicted = val_NN2[2]\n",
        "labels = np.array(gt)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, predicted))\n",
        "print(\"Precision:\", precision_score(labels, predicted, average='macro'))\n",
        "print(\"Recall:\", recall_score(labels, predicted, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(labels, predicted, average='macro'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "4d5tvDWVNL5g",
        "outputId": "81d9c516-4be9-4996-b598-63ac82928183"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(labels, predicted)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix: True vs Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlFb4ku4Cg5d",
        "outputId": "5413c6df-c280-419f-9029-48f441dac9e2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "predicted = val_NN3[2]\n",
        "labels = np.array(gt)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, predicted))\n",
        "print(\"Precision:\", precision_score(labels, predicted, average='macro'))\n",
        "print(\"Recall:\", recall_score(labels, predicted, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(labels, predicted, average='macro'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "8eehWWfNNMno",
        "outputId": "a077ec92-5216-46fb-bd7e-3aa6b1b037ff"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(labels, predicted)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix: True vs Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_88RrXmNeg7"
      },
      "source": [
        "## Run Prediction only from a single plot gene expression file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "JIboNe74N6Kh",
        "outputId": "2299c14d-7375-4c7d-af12-e4f7d88000ca"
      },
      "outputs": [],
      "source": [
        "## Linear Network\n",
        "\n",
        "class LinearExp(torch.nn.Module):\n",
        "    def __init__(self, num_features_exp, hidden_channels, num_classes):\n",
        "        super(LinearExp, self).__init__()\n",
        "\n",
        "        # First Layer\n",
        "        #self.merge = Linear(num_features_exp, hidden_channels)\n",
        "\n",
        "        # MLP Prediction Class\n",
        "        self.mlp_class = torch.nn.Sequential(\n",
        "            torch.nn.Linear(num_features_exp, hidden_channels),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.Linear(hidden_channels, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        exp = data.y\n",
        "        class_out = self.mlp_class(exp)\n",
        "\n",
        "        return class_out\n",
        "\n",
        "\n",
        "def RunTrainingLinear(graph, hidden_channels = 256, num_classes=11, epochs = 50,learning_rate = 0.001, batch_size=32):\n",
        "\n",
        "  num_features_exp = graph[1].y.shape[1]\n",
        "\n",
        "  model = LinearExp(num_features_exp, hidden_channels, num_classes=num_classes)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  model.train()\n",
        "  loader = DataLoader(graph, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  epoch_loss_list = []\n",
        "  epoch_loss = 0\n",
        "\n",
        "  #data = next(iter(loader))\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"Running on:\", device)\n",
        "  model = model.to(device)\n",
        "\n",
        "\n",
        "  for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
        "    for data in loader:\n",
        "        optimizer.zero_grad()\n",
        "        class_out = model(data.to(device))\n",
        "\n",
        "        #Class\n",
        "        gt = data.Class.long()\n",
        "        loss = criterion(class_out, gt)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss /= len(loader)\n",
        "    epoch_loss_list.append(epoch_loss)\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  plt.close()\n",
        "  plt.scatter(range(len(epoch_loss_list)), epoch_loss_list)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "  return(model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuMLf55FPcVs",
        "outputId": "25eafb62-1a77-41c6-a603-6945558d9401"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "vAemKOZ5O6pS",
        "outputId": "12583874-c735-4dc8-bfbe-44836dd5b362"
      },
      "outputs": [],
      "source": [
        "model_lin = RunTrainingLinear(graph_train, epochs=50, num_classes=11, batch_size=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMjH4vg3RTi_"
      },
      "outputs": [],
      "source": [
        "def RunEvaluationGINClassLin(graph, model):\n",
        "\n",
        "  model.eval()\n",
        "  class_out_logits = []\n",
        "  class_out_list = []\n",
        "\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"Running on:\", device)\n",
        "\n",
        "  model.to(device)\n",
        "  i=1\n",
        "\n",
        "  for data in tqdm(graph, desc=\"Eval\"):\n",
        "\n",
        "    #i=i+1\n",
        "    #print(i)\n",
        "    class_out = model(data.to(device))\n",
        "\n",
        "    ## Status\n",
        "    class_out_logits.append(class_out.detach().cpu().numpy())\n",
        "    class_out_list.append(torch.argmax(class_out, dim=1).detach().cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "  return(np.concatenate(class_out_logits), np.concatenate(class_out_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "insGb0TIRg9T",
        "outputId": "91bb6095-c597-4ef1-eddb-9c30623eb521"
      },
      "outputs": [],
      "source": [
        "val_lin = RunEvaluationGINClassLin(graph_val, model_lin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN1XNJszRPf_",
        "outputId": "2b76a904-a5e8-418f-ea84-ba891629b0d4"
      },
      "outputs": [],
      "source": [
        " #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "HmwTyuwwRtnb",
        "outputId": "41e44fed-dc35-42fd-c4ad-e410e06b4f7d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(labels, predicted)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix: True vs Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oICFzRGXE1PB"
      },
      "source": [
        "## Try Different Architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eT5ez1b_E6vK"
      },
      "outputs": [],
      "source": [
        "## Import the network arcitectures\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/GIN_Train/Script')\n",
        "from GAN_V1 import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "0t9A7dhDJJB6",
        "outputId": "7f92091b-f854-4f3c-d41c-48c5f67f2fa6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch_geometric.utils as utils\n",
        "import matplotlib as PL\n",
        "from tqdm import tqdm\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "import torch\n",
        "from torch.nn import BatchNorm1d, Linear\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.utils import add_self_loops\n",
        "from torch_geometric.data import Data\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINConv\n",
        "from torch.nn import Linear\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch_geometric.nn import GATConv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch_geometric.nn import GATConv, global_mean_pool, LayerNorm\n",
        "from torch.nn import Linear\n",
        "\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, softmax\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class GAN(torch.nn.Module):\n",
        "    def __init__(self, num_features_exp, hidden_channels, num_classes):\n",
        "        super(GAN, self).__init__()\n",
        "\n",
        "        # Attention GAT Conv Layers\n",
        "        per_head_hidden_channels = hidden_channels // 5\n",
        "        self.conv1_exp = GATConv(num_features_exp, per_head_hidden_channels, heads=5)\n",
        "        self.conv2_exp = GATConv(per_head_hidden_channels * 5, per_head_hidden_channels, heads=5)\n",
        "\n",
        "\n",
        "       # Batch norm layer\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.dropout = torch.nn.Dropout(0.5) # Add dropout for regularization\n",
        "\n",
        "        # Latent space\n",
        "        self.merge = Linear(hidden_channels, hidden_channels)\n",
        "\n",
        "        # Initiate weights\n",
        "        torch.nn.init.xavier_uniform_(self.merge.weight.data)\n",
        "\n",
        "        # MLP Prediction Class\n",
        "        self.mlp_class = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm1d(hidden_channels),\n",
        "            torch.nn.Dropout(0.5), # Add dropout in the MLP as well\n",
        "            torch.nn.Linear(hidden_channels, num_classes)\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, torch.nn.Linear):\n",
        "                torch.nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        exp, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # GATConv layers require edge_index to be long type\n",
        "        edge_index = edge_index.long()\n",
        "\n",
        "        x_exp, attention_weights_1 = self.conv1_exp(exp, edge_index, return_attention_weights=True)\n",
        "        x_exp = F.leaky_relu(x_exp)\n",
        "        x_exp = self.dropout(self.bn1(x_exp))\n",
        "\n",
        "        x_exp, attention_weights_2 = self.conv2_exp(x_exp, edge_index, return_attention_weights=True)\n",
        "        x_exp = F.leaky_relu(x_exp)\n",
        "        x_exp = self.dropout(self.bn2(x_exp))\n",
        "\n",
        "        x = self.merge(x_exp)\n",
        "        x = F.leaky_relu(x)\n",
        "\n",
        "        class_out = self.mlp_class(global_mean_pool(x, data.batch))\n",
        "\n",
        "        return x, class_out, attention_weights_1, attention_weights_2\n",
        "\n",
        "def RunGAN1(graph,num_classes, hidden_channels = 255, epochs = 50, learning_rate = 0.001, batch_size=16, weight_decay=0.01):\n",
        "\n",
        "  num_features_exp = graph[1].x.shape[1]\n",
        "\n",
        "  model = GAN(num_features_exp, hidden_channels, num_classes)\n",
        "  optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "  model.train()\n",
        "  loader = DataLoader(graph, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  epoch_loss_list = []\n",
        "  epoch_loss = 0\n",
        "\n",
        "  #data = next(iter(loader))\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"Running on:\", device)\n",
        "  model = model.to(device)\n",
        "\n",
        "\n",
        "  for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
        "    for data in loader:\n",
        "        optimizer.zero_grad()\n",
        "        latent, class_out, AT1, AT2 = model(data.to(device))\n",
        "\n",
        "        #Class\n",
        "        gt = data.Class.long()\n",
        "        loss = criterion(class_out, gt)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss /= len(loader)\n",
        "    epoch_loss_list.append(epoch_loss)\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  plt.close()\n",
        "  plt.scatter(range(len(epoch_loss_list)), epoch_loss_list)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "  return(model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LKnojhqFGjjz",
        "outputId": "f459426f-e1ad-43d0-98a6-ccfa98cce70c"
      },
      "outputs": [],
      "source": [
        "model_NN1 = RunGAN1(graph_NN1, num_classes=11, epochs=100, batch_size=1500)\n",
        "torch.save(model_NN1, '/content/drive/My Drive/GIN_Train/Model/Class_model_GAN_NN1.pth')\n",
        "\n",
        "\n",
        "model_NN2 = RunGAN1(graph_NN2, num_classes=11,epochs=100,batch_size=1500)\n",
        "torch.save(model_NN2, '/content/drive/My Drive/GIN_Train/Model/Class_model_GAN_N2.pth')\n",
        "\n",
        "\n",
        "model_NN3 = RunGAN1(graph_NN3, num_classes=11,epochs=100,batch_size=1500)\n",
        "torch.save(model_NN3, '/content/drive/My Drive/GIN_Train/Model/Class_model_GANN_N3.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "Od8cUwVN7fSb",
        "outputId": "b2123246-dd53-4f23-8054-17ec9a7b87bf"
      },
      "outputs": [],
      "source": [
        "model_NN1 = torch.load('/content/drive/My Drive/GIN_Train/Model/Class_model_GAN_NN1.pth')\n",
        "model_NN2 = torch.load('/content/drive/My Drive/GIN_Train/Model/Class_model_GANNN2.pth')\n",
        "model_NN3 = torch.load('/content/drive/My Drive/GIN_Train/Model/Class_model_GANNN3.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-oAVoWVu4Ef"
      },
      "source": [
        "Load validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "jkEByxSHu3Om",
        "outputId": "3a569869-ef80-406b-8dbb-2ca53067d142"
      },
      "outputs": [],
      "source": [
        "graph_val = torch.load(\"/content/drive/My Drive/GIN_Train/Data/Graph_Class_val.pt\")\n",
        "graph_val = runQC(graph_val)\n",
        "graph_val_NN1 = reduceNN(graph_val, hop=1)\n",
        "graph_val_NN2 = reduceNN(graph_val, hop=2)\n",
        "graph_val_NN3 = graph_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gc5oWXfww7L",
        "outputId": "cde9275e-3233-45d4-ef53-948b3b9bccd4"
      },
      "outputs": [],
      "source": [
        "graph_val_NN1[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "UFTEHWW6w_Fw",
        "outputId": "559a3ff0-dfa0-4020-ce4a-2b2ae99ea941"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch_geometric.utils as utils\n",
        "import matplotlib as PL\n",
        "from tqdm import tqdm\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.nn import BatchNorm1d, Linear\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.utils import add_self_loops\n",
        "from torch_geometric.data import Data\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINConv\n",
        "from torch.nn import Linear\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "  model.to(device)\n",
        "  i=1\n",
        "\n",
        "  for data in tqdm(graph, desc=\"Eval\"):\n",
        "\n",
        "    #i=i+1\n",
        "    #print(i)\n",
        "    latent, class_out, AT1, AT2 = model(data.to(device))\n",
        "\n",
        "    ## Latent space\n",
        "    latent_space.append(latent.mean(dim=0, keepdim=True).detach().cpu().numpy())\n",
        "\n",
        "    ## Status\n",
        "    class_out_logits.append(class_out.detach().cpu().numpy())\n",
        "    class_out_list.append(torch.argmax(class_out, dim=1).detach().cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "  return(np.concatenate(latent_space), np.concatenate(class_out_logits), np.concatenate(class_out_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55JVziNt8I33",
        "outputId": "69431728-837d-44fd-e804-6bb898d9a99e"
      },
      "outputs": [],
      "source": [
        "val_NN1 = RunEvaluationGAN(graph_val_NN1, model_NN1)\n",
        "val_NN2 = RunEvaluationGAN(graph_val_NN2, model_NN2)\n",
        "val_NN3 = RunEvaluationGAN(graph_val_NN3, model_NN3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUPI1UEAwmDr",
        "outputId": "6beb581b-d27c-42da-956f-64f90d8d5c56"
      },
      "outputs": [],
      "source": [
        "gt = []\n",
        "for i in tqdm(range(len(graph_val_NN1))):\n",
        "  gt.append(graph_val_NN1[i].Class.detach().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q37ULJWb8RyN",
        "outputId": "4b94996b-71cb-4ab2-8cf3-b5cd3f148c65"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "predicted = val_NN1[2]\n",
        "labels = np.array(gt)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, predicted))\n",
        "print(\"Precision:\", precision_score(labels, predicted, average='macro'))\n",
        "print(\"Recall:\", recall_score(labels, predicted, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(labels, predicted, average='macro'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3_k_b0_8SPG",
        "outputId": "950db8aa-820f-4984-9a6f-86add7b24416"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "predicted = val_NN2[2]\n",
        "labels = np.array(gt)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, predicted))\n",
        "print(\"Precision:\", precision_score(labels, predicted, average='macro'))\n",
        "print(\"Recall:\", recall_score(labels, predicted, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(labels, predicted, average='macro'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNjLc-bW8So3",
        "outputId": "ab99822b-58b0-4b6d-9378-1361020ee01c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "predicted = val_NN3[2]\n",
        "labels = np.array(gt)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, predicted))\n",
        "print(\"Precision:\", precision_score(labels, predicted, average='macro'))\n",
        "print(\"Recall:\", recall_score(labels, predicted, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(labels, predicted, average='macro'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT39IyYsFszm"
      },
      "source": [
        "## Different Data Split: Testset 0.2 of Patients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvVq9dgOFscX"
      },
      "outputs": [],
      "source": [
        "# Read in pd.data.frame\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/GIN_Train/Data/df_subgraph_train_data_split.csv\")\n",
        "df['class_n'] = df['class_n'].astype(int)\n",
        "train, test = train_test_split(df, test_size=0.5, stratify=df[\"class_n\"])\n",
        "\n",
        "df_subgraph = pd.read_csv(\"/content/drive/My Drive/GIN_Train/Data/df_subgraph_train_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXkfKLhhTpEW",
        "outputId": "b4dc00b1-0421-4e32-a2d8-194c101df71e"
      },
      "outputs": [],
      "source": [
        "print(df_subgraph.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "3NkFPfYAR8oD",
        "outputId": "1d11e571-ac1e-4909-fa1c-c5a474c42f77"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "graph_train = torch.load(\"/content/drive/My Drive/GIN_Train/Data/Graph_Class_train.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bF4VCPDzstb"
      },
      "outputs": [],
      "source": [
        "## Import the network arcitectures\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/GIN_Train/Script')\n",
        "\n",
        "from GIN_ClassPred_V2_All_Functions import *\n",
        "from reduceNN import *\n",
        "from runQC import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9THmzFfbT00j",
        "outputId": "199755c8-6fda-4dd0-f5c3-8d30f50710cd"
      },
      "outputs": [],
      "source": [
        "len(graph_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpfS_lnRSa6q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "pat_train = np.asarray(train[\"pat_index\"])\n",
        "filtered_df = df_subgraph[df_subgraph['pat_index'].isin(pat_train)].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "i8mawG-jt0Y2",
        "outputId": "1ac18736-2689-4efc-caf8-56d0fd5c9a1d"
      },
      "outputs": [],
      "source": [
        "filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk6QbM7H1HWV",
        "outputId": "390ce2a8-9f10-473e-da69-b8fb1c1f3df3"
      },
      "outputs": [],
      "source": [
        "np.unique(np.asarray(filtered_df[\"class_n\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjp9LQxA4Rxb",
        "outputId": "4e416395-dfc0-428b-e8a8-20ba31d41667"
      },
      "outputs": [],
      "source": [
        "## Relabel Data\n",
        "original_vector = np.unique(np.asarray(filtered_df[\"class_n\"]))\n",
        "new_labels = [0, 1, 2, 3, 4, 5]\n",
        "\n",
        "mapping = {original: new for original, new in zip(original_vector, new_labels)}\n",
        "\n",
        "# Apply the mapping\n",
        "relabelled_vector = [mapping[item] for item in np.asarray(filtered_df[\"class_n\"])]\n",
        "\n",
        "print(len(relabelled_vector))\n",
        "print(filtered_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nQnzvT64WfI"
      },
      "outputs": [],
      "source": [
        "filtered_df.loc[:, \"class_n\"] = relabelled_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDtfDwnXTgGR"
      },
      "outputs": [],
      "source": [
        "sub_train = np.asarray(filtered_df[\"index_subgraph\"])-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Qy5GEXYt-JA",
        "outputId": "bad15152-0127-4961-f2c4-a9c57bbcb252"
      },
      "outputs": [],
      "source": [
        "graph_train_pat = [graph_train[i] for i in sub_train]\n",
        "\n",
        "class_new = np.asarray(filtered_df[\"class_n\"])\n",
        "for i in tqdm(range(len(graph_train_pat))):\n",
        "  graph_train_pat[i].Class = torch.as_tensor(np.asarray(class_new[i], dtype=\"int8\"), dtype=torch.float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHAiHm8q6CR8",
        "outputId": "92e37fbc-6cfe-432e-d7ad-6916400c66fc"
      },
      "outputs": [],
      "source": [
        "graph_train_pat=runQC(graph_train_pat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWjRVhb95b7h"
      },
      "source": [
        "Preprocess Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfZd9oz77_LT",
        "outputId": "4c917ae2-d459-4c4f-fe04-a662f2edc39b"
      },
      "outputs": [],
      "source": [
        "pat_train = np.asarray(test[\"pat_index\"])\n",
        "filtered_df = df_subgraph[df_subgraph['pat_index'].isin(pat_train)].copy()\n",
        "\n",
        "original_vector = np.unique(np.asarray(filtered_df[\"class_n\"]))\n",
        "original_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RZF2E39eGj7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def runQC(graph,nr_nodes=15):\n",
        "\n",
        "\n",
        "\n",
        "  ## Remove subgraphs with less then 3 hop\n",
        "  nodes = []\n",
        "  for i in tqdm(range(len(graph))):\n",
        "    nodes.append(graph[i].num_nodes)\n",
        "\n",
        "  nodes = np.hstack(nodes)\n",
        "  index=np.where(nodes>=nr_nodes)[0]\n",
        "  graph = [graph[i] for i in index]\n",
        "\n",
        "  index_list_out = index\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  NN = []\n",
        "  for i in tqdm(range(len(graph))):\n",
        "    NN.append(graph[i].neighborhood_index.max().detach().cpu().numpy())\n",
        "\n",
        "  samples = np.hstack(NN)\n",
        "  index=np.where(samples==3)[0]\n",
        "  graph = [graph[i] for i in index]\n",
        "\n",
        "  index_list_out = [index_list_out[i] for i in index]\n",
        "\n",
        "\n",
        "  return(graph,index_list_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqU0L8jfuIEU",
        "outputId": "15dbe8c5-f7cf-4217-d3af-c0d8484fe5fd"
      },
      "outputs": [],
      "source": [
        "new_labels = [0, 1, 2, 3, 4, 5]\n",
        "mapping = {original: new for original, new in zip(original_vector, new_labels)}\n",
        "filtered_df[\"class_n\"] = [mapping[item] for item in np.asarray(filtered_df[\"class_n\"])]\n",
        "\n",
        "sub_train = np.asarray(filtered_df[\"index_subgraph\"])-1\n",
        "graph_test_pat = [graph_train[i] for i in sub_train]\n",
        "\n",
        "class_new = np.asarray(filtered_df[\"class_n\"])\n",
        "for i in tqdm(range(len(graph_test_pat))):\n",
        "  graph_test_pat[i].Class = torch.as_tensor(np.asarray(class_new[i], dtype=\"int8\"), dtype=torch.float)\n",
        "\n",
        "\n",
        "graph_test_pat, index =runQC(graph_test_pat)\n",
        "filtered_df = filtered_df.iloc[index].copy()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynQdEdgzbtSQ",
        "outputId": "25bd4cf9-3741-4f49-bb65-8d33b8287b58"
      },
      "outputs": [],
      "source": [
        "print(np.unique(np.asarray(filtered_df[\"class_n\"])))\n",
        "print(np.unique(np.asarray(filtered_df[\"Class\"])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmrbBwot5gqN"
      },
      "source": [
        "Change Class in graph dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "mfjMYcUCvKt_",
        "outputId": "b1e930d9-40c7-471e-fe46-55e0278f9f9d"
      },
      "outputs": [],
      "source": [
        "model_NN3_split = RunTrainingGIN(graph_train_pat, num_classes=6,epochs=50,batch_size=1500)\n",
        "torch.save(model_NN3_split, '/content/drive/My Drive/GIN_Train/Model/Class_model_NN3_split.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "-kNGUmuwvx5Q",
        "outputId": "2dc20869-9ec1-46a9-836f-716e6609f015"
      },
      "outputs": [],
      "source": [
        "val = RunEvaluationGINClass(graph_test_pat, model_NN3_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyBvqCeWv1f-",
        "outputId": "895f978d-b299-4916-9bf0-40dc09457dca"
      },
      "outputs": [],
      "source": [
        "gt = []\n",
        "for i in tqdm(range(len(graph_test_pat))):\n",
        "  gt.append(graph_test_pat[i].Class.detach().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOJon9U00jRA",
        "outputId": "e6c17828-54dc-4dc1-b836-3d3def323a7f"
      },
      "outputs": [],
      "source": [
        "np.unique(gt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ1dfqLvv_1i",
        "outputId": "e4a5d428-d444-4818-a1c2-0045e03971fd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "predicted = val[2]\n",
        "labels = np.array(gt)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, predicted))\n",
        "print(\"Precision:\", precision_score(labels, predicted, average='macro'))\n",
        "print(\"Recall:\", recall_score(labels, predicted, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(labels, predicted, average='macro'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "tYfDFBZwyKNd",
        "outputId": "680c7e61-fc04-4d06-d6b3-451ae3ab1bea"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(labels, predicted)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix: True vs Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "X81T0u9GdXK3",
        "outputId": "4a46cb46-36ac-4b5a-a80e-b039ebea5c6e"
      },
      "outputs": [],
      "source": [
        "## Prediction on patient level\n",
        "filtered_df[\"prediction\"] = predicted\n",
        "filtered_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VAj60bARf43Y",
        "outputId": "9c07dbc4-7563-4e4c-9d9f-81ca1139ed69"
      },
      "outputs": [],
      "source": [
        "grouped = filtered_df.groupby(['pat_index', 'prediction']).size().reset_index(name='counts').copy()\n",
        "total_counts = grouped.groupby('pat_index')['counts'].transform('sum')\n",
        "grouped['percentage'] = (grouped['counts'] / total_counts) * 100\n",
        "grouped\n",
        "\n",
        "#len(np.unique(np.array(grouped[\"pat_index\"])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "rZTilH9bgY_e",
        "outputId": "33fa6fd8-3935-473c-fcae-8fcc1fe6577c"
      },
      "outputs": [],
      "source": [
        "class_df = filtered_df.groupby(['pat_index', 'class_n']).size().reset_index(name='counts').copy()\n",
        "class_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "CXfAEVdHg9-v",
        "outputId": "cc53e0c2-66a9-499f-8df5-164cd007f353"
      },
      "outputs": [],
      "source": [
        "max_percentage_idx = grouped.groupby('pat_index')['percentage'].idxmax()\n",
        "max_percentage_rows = grouped.loc[max_percentage_idx]\n",
        "max_percentage_rows[\"GT\"] = np.array(class_df[\"class_n\"], dtype=\"int8\")\n",
        "max_percentage_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "cey0A599haR4",
        "outputId": "8e255c60-9ee9-4734-f0e7-b570a87406cd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(max_percentage_rows[\"GT\"], max_percentage_rows[\"prediction\"])\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Reds')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix: True vs Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoZPjjICjPdm",
        "outputId": "da4bebf4-2b9d-40a9-bd55-e397b7d44149"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "predicted = max_percentage_rows[\"prediction\"]\n",
        "labels = max_percentage_rows[\"GT\"]\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, predicted))\n",
        "print(\"Precision:\", precision_score(labels, predicted, average='macro'))\n",
        "print(\"Recall:\", recall_score(labels, predicted, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(labels, predicted, average='macro'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predicted))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
