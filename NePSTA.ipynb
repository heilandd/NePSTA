{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMClL7sHHeqC"
      },
      "source": [
        "# NePSTA GNN Network\n",
        "\n",
        "This notebook contains the full analysis of the ST Pathology framework. We start with the module to predict the Heidelberg classifier subgroups from spatially resolved transcriptomics using a 3-hop subgraph.\n",
        "\n",
        "Abstract: The diagnostic landscape of brain tumors has recently evolved to integrate comprehensive molecular markers alongside traditional histopathological evaluation. Foremost, genome-wide DNA methylation profiling and next generation sequencing (NGS) has become a cornerstone in classifying Central Nervous System (CNS) tumors, as recognized by its inclusion into the 2021 WHO classification. Despite its diagnostic precision, a limiting requirement for NGS and methylation profiling is sufficient DNA quality and quantity which restricts its feasibility, especially in cases with small biopsy samples or low tumor cell content, both frequent challenges in specimen of diffusely growing CNS lesions. Addressing these challenges, we demonstrate a novel application, namely NePSTA (NeuroPathology Spatial Transcriptomic Analysis), which is capable of generating comprehensive morphological and molecular neuropathological diagnostics from single 5 Âµm tissue sections. Our framework employs 10x Visium spatial transcriptomics with graph neural networks for automated histological and molecular evaluations. Trained and evaluated across 130 patients with CNS malignancies and healthy donors across four medical centers, NePSTA integrates spatial gene expression data and inferred CNAs to predict tissue histology and methylation-based subclasses with high accuracy. Further, we demonstrate the ability to reconstruct immunohistochemistry and genotype profiling on single thin slides of minute tissue biopsies. Our approach has minimal tissue requirements, often inadequate for conventional molecular diagnostics, demonstrating the potential to transform neuropathological diagnostics and enhance tumor subtype identification with implications for fast and precise diagnostic work-up.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbvL-XHb2YzS"
      },
      "source": [
        "## Instalation of packages and upload functions\n",
        "The notebook is optimized to use it in google colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0lGjQ4QHjEc",
        "outputId": "6ab3b6fb-c72e-4d68-9765-1378046d867c"
      },
      "outputs": [],
      "source": [
        "## Install Pytorch geometric\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N-b8Vq-2YzU",
        "outputId": "43da5488-bbaf-40f6-e987-e42f5a792d67"
      },
      "outputs": [],
      "source": [
        "## Clone the github\n",
        "!git clone https://github.com/heilandd/NePSTA.git\n",
        "%cd NePSTA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ngsYdGs2iUn"
      },
      "source": [
        "We have uploaded a smal test dataset with 1000 subgraphs that can be used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmdpXRqwIExW"
      },
      "outputs": [],
      "source": [
        "## Import the network arcitectures\n",
        "import sys\n",
        "sys.path.append('/content/NePSTA/Model')\n",
        "from GIN_V3 import *\n",
        "sys.path.append('/content/NePSTA/Function_py')\n",
        "from reduceNN import *\n",
        "from runQC import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF4kZ_O-nyHj"
      },
      "source": [
        "## Import data and run quality controll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "wIYQeZFN4_hM",
        "outputId": "5d5a7f59-f81d-420f-e42e-65af9b53c45b"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "gdown_url = \"https://drive.google.com/uc?export=download&id=1evnmD6LdE-QPF4_lxkTCcQ9QsVCx6r4e\"\n",
        "gdown.download(gdown_url, \"graph.pt\", quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC83BzeYnxRz",
        "outputId": "4b556e9d-dd8d-4248-ab35-8981e13209e4"
      },
      "outputs": [],
      "source": [
        "graph_train = torch.load(\"/content/NePSTA/graph.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv7QT_X_oCAP",
        "outputId": "c6ace4f5-20a4-431b-9de5-013a9492c4d5"
      },
      "outputs": [],
      "source": [
        "graph_train = runQC(graph_train)\n",
        "\n",
        "## The runQC output a list of the graph object in [0] and a vector of the subgraphs that are added to the final list.\n",
        "\n",
        "graph_train = graph_train[0]\n",
        "\n",
        "## Representative example\n",
        "graph_train[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LLkPsM-oF51",
        "outputId": "995ea73c-c75e-485c-9533-8dc72d613790"
      },
      "outputs": [],
      "source": [
        "graph_NN1 = reduceNN(graph_train, hop=1)\n",
        "graph_NN2 = reduceNN(graph_train, hop=2)\n",
        "graph_NN3 = graph_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "BRiPIg4doLeD",
        "outputId": "9df741e9-929d-479f-b140-caa34e06fa1c"
      },
      "outputs": [],
      "source": [
        "model_NN1 = RunTrainingGIN(graph_NN1, num_classes=11, epochs=200, batch_size=1500)\n",
        "model_NN2 = RunTrainingGIN(graph_NN2, num_classes=11,epochs=200,batch_size=1500)\n",
        "model_NN3 = RunTrainingGIN(graph_NN3, num_classes=11,epochs=200,batch_size=1500)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR63tkwdA14l"
      },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoq24NnbBXCQ"
      },
      "source": [
        "## Run Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GqSe_keJZl0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch_geometric.utils as utils\n",
        "import matplotlib as PL\n",
        "from tqdm import tqdm\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.nn import BatchNorm1d, Linear\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.utils import add_self_loops\n",
        "from torch_geometric.data import Data\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINConv\n",
        "from torch.nn import Linear\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "import torch.nn as nn\n",
        "\n",
        "def RunEvaluationGINClass1(graph, model):\n",
        "\n",
        "  model.eval()\n",
        "  latent_space = []\n",
        "  class_out_logits = []\n",
        "  class_out_list = []\n",
        "\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"Running on:\", device)\n",
        "\n",
        "  model.to(device)\n",
        "  i=1\n",
        "\n",
        "  for data in tqdm(graph, desc=\"Eval\"):\n",
        "\n",
        "    #i=i+1\n",
        "    #print(i)\n",
        "    latent, class_out = model(data.to(device))\n",
        "\n",
        "    ## Latent space\n",
        "    latent_space.append(latent.mean(dim=0, keepdim=True).detach().cpu().numpy())\n",
        "\n",
        "    ## Status\n",
        "    class_out_logits.append(class_out.detach().cpu().numpy())\n",
        "    class_out_list.append(torch.argmax(class_out, dim=1).detach().cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "  return(np.concatenate(latent_space), np.concatenate(class_out_logits), np.concatenate(class_out_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JDi0PyyMs5O"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvQE7M3vBH-k"
      },
      "outputs": [],
      "source": [
        "val_NN1 = RunEvaluationGINClass1(graph_val_NN1, model_NN1)\n",
        "val_NN2 = RunEvaluationGINClass1(graph_val_NN2, model_NN2)\n",
        "val_NN3 = RunEvaluationGINClass1(graph_val_NN3, model_NN3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iT8hwu4BowS"
      },
      "outputs": [],
      "source": [
        "gt = []\n",
        "for i in tqdm(range(len(graph_val_NN1))):\n",
        "  gt.append(graph_val_NN1[i].Class.detach().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mqXUcKPB7GD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "predicted = val_NN1[2]\n",
        "labels = np.array(gt)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, predicted))\n",
        "print(\"Precision:\", precision_score(labels, predicted, average='macro'))\n",
        "print(\"Recall:\", recall_score(labels, predicted, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(labels, predicted, average='macro'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGC0xfoCNDGu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(labels, predicted)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix: True vs Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSmxQ7JKCgUB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "predicted = val_NN2[2]\n",
        "labels = np.array(gt)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, predicted))\n",
        "print(\"Precision:\", precision_score(labels, predicted, average='macro'))\n",
        "print(\"Recall:\", recall_score(labels, predicted, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(labels, predicted, average='macro'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d5tvDWVNL5g"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(labels, predicted)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix: True vs Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlFb4ku4Cg5d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "predicted = val_NN3[2]\n",
        "labels = np.array(gt)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, predicted))\n",
        "print(\"Precision:\", precision_score(labels, predicted, average='macro'))\n",
        "print(\"Recall:\", recall_score(labels, predicted, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(labels, predicted, average='macro'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eehWWfNNMno"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(labels, predicted)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix: True vs Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_88RrXmNeg7"
      },
      "source": [
        "## Run Prediction only from a single plot gene expression file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIboNe74N6Kh"
      },
      "outputs": [],
      "source": [
        "## Linear Network\n",
        "\n",
        "class LinearExp(torch.nn.Module):\n",
        "    def __init__(self, num_features_exp, hidden_channels, num_classes):\n",
        "        super(LinearExp, self).__init__()\n",
        "\n",
        "        # First Layer\n",
        "        #self.merge = Linear(num_features_exp, hidden_channels)\n",
        "\n",
        "        # MLP Prediction Class\n",
        "        self.mlp_class = torch.nn.Sequential(\n",
        "            torch.nn.Linear(num_features_exp, hidden_channels),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.Linear(hidden_channels, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        exp = data.y\n",
        "        class_out = self.mlp_class(exp)\n",
        "\n",
        "        return class_out\n",
        "\n",
        "\n",
        "def RunTrainingLinear(graph, hidden_channels = 256, num_classes=11, epochs = 50,learning_rate = 0.001, batch_size=32):\n",
        "\n",
        "  num_features_exp = graph[1].y.shape[1]\n",
        "\n",
        "  model = LinearExp(num_features_exp, hidden_channels, num_classes=num_classes)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  model.train()\n",
        "  loader = DataLoader(graph, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  epoch_loss_list = []\n",
        "  epoch_loss = 0\n",
        "\n",
        "  #data = next(iter(loader))\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"Running on:\", device)\n",
        "  model = model.to(device)\n",
        "\n",
        "\n",
        "  for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
        "    for data in loader:\n",
        "        optimizer.zero_grad()\n",
        "        class_out = model(data.to(device))\n",
        "\n",
        "        #Class\n",
        "        gt = data.Class.long()\n",
        "        loss = criterion(class_out, gt)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss /= len(loader)\n",
        "    epoch_loss_list.append(epoch_loss)\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  plt.close()\n",
        "  plt.scatter(range(len(epoch_loss_list)), epoch_loss_list)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "  return(model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuMLf55FPcVs"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAemKOZ5O6pS"
      },
      "outputs": [],
      "source": [
        "model_lin = RunTrainingLinear(graph_train, epochs=50, num_classes=11, batch_size=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMjH4vg3RTi_"
      },
      "outputs": [],
      "source": [
        "def RunEvaluationGINClassLin(graph, model):\n",
        "\n",
        "  model.eval()\n",
        "  class_out_logits = []\n",
        "  class_out_list = []\n",
        "\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"Running on:\", device)\n",
        "\n",
        "  model.to(device)\n",
        "  i=1\n",
        "\n",
        "  for data in tqdm(graph, desc=\"Eval\"):\n",
        "\n",
        "    #i=i+1\n",
        "    #print(i)\n",
        "    class_out = model(data.to(device))\n",
        "\n",
        "    ## Status\n",
        "    class_out_logits.append(class_out.detach().cpu().numpy())\n",
        "    class_out_list.append(torch.argmax(class_out, dim=1).detach().cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "  return(np.concatenate(class_out_logits), np.concatenate(class_out_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "insGb0TIRg9T"
      },
      "outputs": [],
      "source": [
        "val_lin = RunEvaluationGINClassLin(graph_val, model_lin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zN1XNJszRPf_"
      },
      "outputs": [],
      "source": [
        " #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmwTyuwwRtnb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(labels, predicted)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix: True vs Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oICFzRGXE1PB"
      },
      "source": [
        "## Try Different Architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eT5ez1b_E6vK"
      },
      "outputs": [],
      "source": [
        "## Import the network arcitectures\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/GIN_Train/Script')\n",
        "from GAN_V1 import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t9A7dhDJJB6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch_geometric.utils as utils\n",
        "import matplotlib as PL\n",
        "from tqdm import tqdm\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "import torch\n",
        "from torch.nn import BatchNorm1d, Linear\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.utils import add_self_loops\n",
        "from torch_geometric.data import Data\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINConv\n",
        "from torch.nn import Linear\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch_geometric.nn import GATConv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch_geometric.nn import GATConv, global_mean_pool, LayerNorm\n",
        "from torch.nn import Linear\n",
        "\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, softmax\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class GAN(torch.nn.Module):\n",
        "    def __init__(self, num_features_exp, hidden_channels, num_classes):\n",
        "        super(GAN, self).__init__()\n",
        "\n",
        "        # Attention GAT Conv Layers\n",
        "        per_head_hidden_channels = hidden_channels // 5\n",
        "        self.conv1_exp = GATConv(num_features_exp, per_head_hidden_channels, heads=5)\n",
        "        self.conv2_exp = GATConv(per_head_hidden_channels * 5, per_head_hidden_channels, heads=5)\n",
        "\n",
        "\n",
        "       # Batch norm layer\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.dropout = torch.nn.Dropout(0.5) # Add dropout for regularization\n",
        "\n",
        "        # Latent space\n",
        "        self.merge = Linear(hidden_channels, hidden_channels)\n",
        "\n",
        "        # Initiate weights\n",
        "        torch.nn.init.xavier_uniform_(self.merge.weight.data)\n",
        "\n",
        "        # MLP Prediction Class\n",
        "        self.mlp_class = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm1d(hidden_channels),\n",
        "            torch.nn.Dropout(0.5), # Add dropout in the MLP as well\n",
        "            torch.nn.Linear(hidden_channels, num_classes)\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, torch.nn.Linear):\n",
        "                torch.nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        exp, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # GATConv layers require edge_index to be long type\n",
        "        edge_index = edge_index.long()\n",
        "\n",
        "        x_exp, attention_weights_1 = self.conv1_exp(exp, edge_index, return_attention_weights=True)\n",
        "        x_exp = F.leaky_relu(x_exp)\n",
        "        x_exp = self.dropout(self.bn1(x_exp))\n",
        "\n",
        "        x_exp, attention_weights_2 = self.conv2_exp(x_exp, edge_index, return_attention_weights=True)\n",
        "        x_exp = F.leaky_relu(x_exp)\n",
        "        x_exp = self.dropout(self.bn2(x_exp))\n",
        "\n",
        "        x = self.merge(x_exp)\n",
        "        x = F.leaky_relu(x)\n",
        "\n",
        "        class_out = self.mlp_class(global_mean_pool(x, data.batch))\n",
        "\n",
        "        return x, class_out, attention_weights_1, attention_weights_2\n",
        "\n",
        "def RunGAN1(graph,num_classes, hidden_channels = 255, epochs = 50, learning_rate = 0.001, batch_size=16, weight_decay=0.01):\n",
        "\n",
        "  num_features_exp = graph[1].x.shape[1]\n",
        "\n",
        "  model = GAN(num_features_exp, hidden_channels, num_classes)\n",
        "  optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "  model.train()\n",
        "  loader = DataLoader(graph, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  epoch_loss_list = []\n",
        "  epoch_loss = 0\n",
        "\n",
        "  #data = next(iter(loader))\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"Running on:\", device)\n",
        "  model = model.to(device)\n",
        "\n",
        "\n",
        "  for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
        "    for data in loader:\n",
        "        optimizer.zero_grad()\n",
        "        latent, class_out, AT1, AT2 = model(data.to(device))\n",
        "\n",
        "        #Class\n",
        "        gt = data.Class.long()\n",
        "        loss = criterion(class_out, gt)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss /= len(loader)\n",
        "    epoch_loss_list.append(epoch_loss)\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  plt.close()\n",
        "  plt.scatter(range(len(epoch_loss_list)), epoch_loss_list)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "  return(model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKnojhqFGjjz"
      },
      "outputs": [],
      "source": [
        "model_NN1 = RunGAN1(graph_NN1, num_classes=11, epochs=100, batch_size=1500)\n",
        "torch.save(model_NN1, '/content/drive/My Drive/GIN_Train/Model/Class_model_GAN_NN1.pth')\n",
        "\n",
        "\n",
        "model_NN2 = RunGAN1(graph_NN2, num_classes=11,epochs=100,batch_size=1500)\n",
        "torch.save(model_NN2, '/content/drive/My Drive/GIN_Train/Model/Class_model_GAN_N2.pth')\n",
        "\n",
        "\n",
        "model_NN3 = RunGAN1(graph_NN3, num_classes=11,epochs=100,batch_size=1500)\n",
        "torch.save(model_NN3, '/content/drive/My Drive/GIN_Train/Model/Class_model_GANN_N3.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Od8cUwVN7fSb"
      },
      "outputs": [],
      "source": [
        "model_NN1 = torch.load('/content/drive/My Drive/GIN_Train/Model/Class_model_GAN_NN1.pth')\n",
        "model_NN2 = torch.load('/content/drive/My Drive/GIN_Train/Model/Class_model_GANNN2.pth')\n",
        "model_NN3 = torch.load('/content/drive/My Drive/GIN_Train/Model/Class_model_GANNN3.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-oAVoWVu4Ef"
      },
      "source": [
        "Load validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkEByxSHu3Om"
      },
      "outputs": [],
      "source": [
        "graph_val = torch.load(\"/content/drive/My Drive/GIN_Train/Data/Graph_Class_val.pt\")\n",
        "graph_val = runQC(graph_val)\n",
        "graph_val_NN1 = reduceNN(graph_val, hop=1)\n",
        "graph_val_NN2 = reduceNN(graph_val, hop=2)\n",
        "graph_val_NN3 = graph_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gc5oWXfww7L"
      },
      "outputs": [],
      "source": [
        "graph_val_NN1[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFTEHWW6w_Fw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch_geometric.utils as utils\n",
        "import matplotlib as PL\n",
        "from tqdm import tqdm\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.nn import BatchNorm1d, Linear\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.utils import add_self_loops\n",
        "from torch_geometric.data import Data\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINConv\n",
        "from torch.nn import Linear\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "  model.to(device)\n",
        "  i=1\n",
        "\n",
        "  for data in tqdm(graph, desc=\"Eval\"):\n",
        "\n",
        "    #i=i+1\n",
        "    #print(i)\n",
        "    latent, class_out, AT1, AT2 = model(data.to(device))\n",
        "\n",
        "    ## Latent space\n",
        "    latent_space.append(latent.mean(dim=0, keepdim=True).detach().cpu().numpy())\n",
        "\n",
        "    ## Status\n",
        "    class_out_logits.append(class_out.detach().cpu().numpy())\n",
        "    class_out_list.append(torch.argmax(class_out, dim=1).detach().cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "  return(np.concatenate(latent_space), np.concatenate(class_out_logits), np.concatenate(class_out_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55JVziNt8I33"
      },
      "outputs": [],
      "source": [
        "val_NN1 = RunEvaluationGAN(graph_val_NN1, model_NN1)\n",
        "val_NN2 = RunEvaluationGAN(graph_val_NN2, model_NN2)\n",
        "val_NN3 = RunEvaluationGAN(graph_val_NN3, model_NN3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUPI1UEAwmDr"
      },
      "outputs": [],
      "source": [
        "gt = []\n",
        "for i in tqdm(range(len(graph_val_NN1))):\n",
        "  gt.append(graph_val_NN1[i].Class.detach().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q37ULJWb8RyN"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "predicted = val_NN1[2]\n",
        "labels = np.array(gt)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, predicted))\n",
        "print(\"Precision:\", precision_score(labels, predicted, average='macro'))\n",
        "print(\"Recall:\", recall_score(labels, predicted, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(labels, predicted, average='macro'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3_k_b0_8SPG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "predicted = val_NN2[2]\n",
        "labels = np.array(gt)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, predicted))\n",
        "print(\"Precision:\", precision_score(labels, predicted, average='macro'))\n",
        "print(\"Recall:\", recall_score(labels, predicted, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(labels, predicted, average='macro'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNjLc-bW8So3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "predicted = val_NN3[2]\n",
        "labels = np.array(gt)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, predicted))\n",
        "print(\"Precision:\", precision_score(labels, predicted, average='macro'))\n",
        "print(\"Recall:\", recall_score(labels, predicted, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(labels, predicted, average='macro'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT39IyYsFszm"
      },
      "source": [
        "## Different Data Split: Testset 0.2 of Patients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvVq9dgOFscX"
      },
      "outputs": [],
      "source": [
        "# Read in pd.data.frame\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/GIN_Train/Data/df_subgraph_train_data_split.csv\")\n",
        "df['class_n'] = df['class_n'].astype(int)\n",
        "train, test = train_test_split(df, test_size=0.5, stratify=df[\"class_n\"])\n",
        "\n",
        "df_subgraph = pd.read_csv(\"/content/drive/My Drive/GIN_Train/Data/df_subgraph_train_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXkfKLhhTpEW"
      },
      "outputs": [],
      "source": [
        "print(df_subgraph.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NkFPfYAR8oD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "graph_train = torch.load(\"/content/drive/My Drive/GIN_Train/Data/Graph_Class_train.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bF4VCPDzstb"
      },
      "outputs": [],
      "source": [
        "## Import the network arcitectures\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/GIN_Train/Script')\n",
        "\n",
        "from GIN_ClassPred_V2_All_Functions import *\n",
        "from reduceNN import *\n",
        "from runQC import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9THmzFfbT00j"
      },
      "outputs": [],
      "source": [
        "len(graph_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpfS_lnRSa6q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "pat_train = np.asarray(train[\"pat_index\"])\n",
        "filtered_df = df_subgraph[df_subgraph['pat_index'].isin(pat_train)].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8mawG-jt0Y2"
      },
      "outputs": [],
      "source": [
        "filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uk6QbM7H1HWV"
      },
      "outputs": [],
      "source": [
        "np.unique(np.asarray(filtered_df[\"class_n\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vjp9LQxA4Rxb"
      },
      "outputs": [],
      "source": [
        "## Relabel Data\n",
        "original_vector = np.unique(np.asarray(filtered_df[\"class_n\"]))\n",
        "new_labels = [0, 1, 2, 3, 4, 5]\n",
        "\n",
        "mapping = {original: new for original, new in zip(original_vector, new_labels)}\n",
        "\n",
        "# Apply the mapping\n",
        "relabelled_vector = [mapping[item] for item in np.asarray(filtered_df[\"class_n\"])]\n",
        "\n",
        "print(len(relabelled_vector))\n",
        "print(filtered_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nQnzvT64WfI"
      },
      "outputs": [],
      "source": [
        "filtered_df.loc[:, \"class_n\"] = relabelled_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDtfDwnXTgGR"
      },
      "outputs": [],
      "source": [
        "sub_train = np.asarray(filtered_df[\"index_subgraph\"])-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Qy5GEXYt-JA"
      },
      "outputs": [],
      "source": [
        "graph_train_pat = [graph_train[i] for i in sub_train]\n",
        "\n",
        "class_new = np.asarray(filtered_df[\"class_n\"])\n",
        "for i in tqdm(range(len(graph_train_pat))):\n",
        "  graph_train_pat[i].Class = torch.as_tensor(np.asarray(class_new[i], dtype=\"int8\"), dtype=torch.float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHAiHm8q6CR8"
      },
      "outputs": [],
      "source": [
        "graph_train_pat=runQC(graph_train_pat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWjRVhb95b7h"
      },
      "source": [
        "Preprocess Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfZd9oz77_LT"
      },
      "outputs": [],
      "source": [
        "pat_train = np.asarray(test[\"pat_index\"])\n",
        "filtered_df = df_subgraph[df_subgraph['pat_index'].isin(pat_train)].copy()\n",
        "\n",
        "original_vector = np.unique(np.asarray(filtered_df[\"class_n\"]))\n",
        "original_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RZF2E39eGj7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def runQC(graph,nr_nodes=15):\n",
        "\n",
        "\n",
        "\n",
        "  ## Remove subgraphs with less then 3 hop\n",
        "  nodes = []\n",
        "  for i in tqdm(range(len(graph))):\n",
        "    nodes.append(graph[i].num_nodes)\n",
        "\n",
        "  nodes = np.hstack(nodes)\n",
        "  index=np.where(nodes>=nr_nodes)[0]\n",
        "  graph = [graph[i] for i in index]\n",
        "\n",
        "  index_list_out = index\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  NN = []\n",
        "  for i in tqdm(range(len(graph))):\n",
        "    NN.append(graph[i].neighborhood_index.max().detach().cpu().numpy())\n",
        "\n",
        "  samples = np.hstack(NN)\n",
        "  index=np.where(samples==3)[0]\n",
        "  graph = [graph[i] for i in index]\n",
        "\n",
        "  index_list_out = [index_list_out[i] for i in index]\n",
        "\n",
        "\n",
        "  return(graph,index_list_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqU0L8jfuIEU"
      },
      "outputs": [],
      "source": [
        "new_labels = [0, 1, 2, 3, 4, 5]\n",
        "mapping = {original: new for original, new in zip(original_vector, new_labels)}\n",
        "filtered_df[\"class_n\"] = [mapping[item] for item in np.asarray(filtered_df[\"class_n\"])]\n",
        "\n",
        "sub_train = np.asarray(filtered_df[\"index_subgraph\"])-1\n",
        "graph_test_pat = [graph_train[i] for i in sub_train]\n",
        "\n",
        "class_new = np.asarray(filtered_df[\"class_n\"])\n",
        "for i in tqdm(range(len(graph_test_pat))):\n",
        "  graph_test_pat[i].Class = torch.as_tensor(np.asarray(class_new[i], dtype=\"int8\"), dtype=torch.float)\n",
        "\n",
        "\n",
        "graph_test_pat, index =runQC(graph_test_pat)\n",
        "filtered_df = filtered_df.iloc[index].copy()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynQdEdgzbtSQ"
      },
      "outputs": [],
      "source": [
        "print(np.unique(np.asarray(filtered_df[\"class_n\"])))\n",
        "print(np.unique(np.asarray(filtered_df[\"Class\"])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmrbBwot5gqN"
      },
      "source": [
        "Change Class in graph dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfjMYcUCvKt_"
      },
      "outputs": [],
      "source": [
        "model_NN3_split = RunTrainingGIN(graph_train_pat, num_classes=6,epochs=50,batch_size=1500)\n",
        "torch.save(model_NN3_split, '/content/drive/My Drive/GIN_Train/Model/Class_model_NN3_split.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kNGUmuwvx5Q"
      },
      "outputs": [],
      "source": [
        "val = RunEvaluationGINClass(graph_test_pat, model_NN3_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyBvqCeWv1f-"
      },
      "outputs": [],
      "source": [
        "gt = []\n",
        "for i in tqdm(range(len(graph_test_pat))):\n",
        "  gt.append(graph_test_pat[i].Class.detach().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOJon9U00jRA"
      },
      "outputs": [],
      "source": [
        "np.unique(gt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQ1dfqLvv_1i"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "predicted = val[2]\n",
        "labels = np.array(gt)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, predicted))\n",
        "print(\"Precision:\", precision_score(labels, predicted, average='macro'))\n",
        "print(\"Recall:\", recall_score(labels, predicted, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(labels, predicted, average='macro'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYfDFBZwyKNd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(labels, predicted)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix: True vs Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X81T0u9GdXK3"
      },
      "outputs": [],
      "source": [
        "## Prediction on patient level\n",
        "filtered_df[\"prediction\"] = predicted\n",
        "filtered_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAj60bARf43Y"
      },
      "outputs": [],
      "source": [
        "grouped = filtered_df.groupby(['pat_index', 'prediction']).size().reset_index(name='counts').copy()\n",
        "total_counts = grouped.groupby('pat_index')['counts'].transform('sum')\n",
        "grouped['percentage'] = (grouped['counts'] / total_counts) * 100\n",
        "grouped\n",
        "\n",
        "#len(np.unique(np.array(grouped[\"pat_index\"])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZTilH9bgY_e"
      },
      "outputs": [],
      "source": [
        "class_df = filtered_df.groupby(['pat_index', 'class_n']).size().reset_index(name='counts').copy()\n",
        "class_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXfAEVdHg9-v"
      },
      "outputs": [],
      "source": [
        "max_percentage_idx = grouped.groupby('pat_index')['percentage'].idxmax()\n",
        "max_percentage_rows = grouped.loc[max_percentage_idx]\n",
        "max_percentage_rows[\"GT\"] = np.array(class_df[\"class_n\"], dtype=\"int8\")\n",
        "max_percentage_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cey0A599haR4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(max_percentage_rows[\"GT\"], max_percentage_rows[\"prediction\"])\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Reds')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix: True vs Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoZPjjICjPdm"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "predicted = max_percentage_rows[\"prediction\"]\n",
        "labels = max_percentage_rows[\"GT\"]\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, predicted))\n",
        "print(\"Precision:\", precision_score(labels, predicted, average='macro'))\n",
        "print(\"Recall:\", recall_score(labels, predicted, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(labels, predicted, average='macro'))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predicted))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
